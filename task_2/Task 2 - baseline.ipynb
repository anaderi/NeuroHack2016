{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.linalg import eig\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_FILE = \"train.h5\"\n",
    "TEST_FILE = \"test.h5\"\n",
    "SAMPLING_RATE = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CHANNEL_NAMES = np.array(['T5', 'T3', 'F7', 'F3', 'C3', 'P3', 'Fp1', 'Fpz', 'A1', 'O1', 'Cz', 'Oz', 'Fz', 'Pz', 'O2', 'A2', 'Fp2', 'P4', 'C4', 'F4', 'F8', 'T4', 'T6', 'AUX'])\n",
    "CHANNELS_TO_DISCARD = ['A1', 'A2', 'AUX']\n",
    "EYE_CHANNEL = \"Fp1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, sampling_rate, order=5):\n",
    "    nyq_freq = sampling_rate*0.5\n",
    "    low = lowcut/nyq_freq\n",
    "    high = highcut/nyq_freq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_high_low_pass(lowcut, highcut, sampling_rate, order=5):\n",
    "    nyq_freq = sampling_rate*0.5\n",
    "    lower_bound = lowcut/nyq_freq\n",
    "    higher_bound = highcut/nyq_freq\n",
    "    b_high, a_high = butter(order, lower_bound, btype='high')\n",
    "    b_low, a_low = butter(order, higher_bound, btype='low')\n",
    "    return b_high, a_high, b_low, a_low\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, sampling_rate, order=5, how_to_filt = 'separately'):\n",
    "    if how_to_filt == 'separately':\n",
    "        b_high, a_high, b_low, a_low = butter_high_low_pass(lowcut, highcut, sampling_rate, order=order)\n",
    "        y = lfilter(b_high, a_high, data)\n",
    "        y = lfilter(b_low, a_low, y)\n",
    "    elif how_to_filt == 'simultaneously':\n",
    "        b, a = butter_bandpass(lowcut, highcut, sampling_rate, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_outliers(data_raw, iter_numb):\n",
    "    data = np.copy(data_raw)\n",
    "    data_pwr = np.sqrt(np.sum(data**2, 0))\n",
    "    \n",
    "    for i in range(iter_numb):\n",
    "        X_mean = np.mean(data_pwr)\n",
    "        X_std = np.std(data_pwr)\n",
    "        mask = np.abs(data_pwr - X_mean) < 2.5*np.abs(X_std)\n",
    "        data = data[:, mask]\n",
    "        data_pwr = data_pwr[mask]\n",
    "        print('Samples left after outliers removal: %d' % data_pwr.shape[0])\n",
    "        \n",
    "    return data, mask\n",
    "\n",
    "\n",
    "def remove_eog_simple(data, eyechan, N_art_comp=3):    \n",
    "    only_eye_chan = data[eyechan, :]\n",
    "    exceed_mask = only_eye_chan > 3*np.mean(np.absolute(only_eye_chan))\n",
    "    print('Number of samples identified as containing eye artifacts: %d' % np.sum(exceed_mask))\n",
    "    U, S, V = np.linalg.svd(data[:, exceed_mask[0,:]], full_matrices=True)\n",
    "    M_eog = np.eye(U.shape[0])-np.dot(U[:,0:N_art_comp],U[:,0:N_art_comp].T)\n",
    "    \n",
    "    return np.dot(M_eog,data), M_eog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outer_n(n):\n",
    "    return np.array(list(range(n))+list(range(-n,0)))\n",
    "\n",
    "def whitener(C, rtol=1e-15):\n",
    "    e, E = np.linalg.eigh(C)\n",
    "    return reduce(np.dot, [E, np.diag(np.where(e > np.max(e) * rtol, e, np.inf)**-0.5), E.T])\n",
    "\n",
    "def csp_base(C_a, C_b):\n",
    "    P = whitener(C_a + C_b)\n",
    "    P_C_b = reduce(np.dot, [P, C_b, P.T])\n",
    "    _, _, B = np.linalg.svd((P_C_b))\n",
    "    return np.dot(B, P.T)\n",
    "\n",
    "def csp(C_a, C_b, m):\n",
    "    W = csp_base(C_a, C_b)\n",
    "    assert W.shape[1] >= 2*m\n",
    "    return W[outer_n(m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_CSP_matr(data, states_labels, main_state, N_comp, other_state=None, mode='one_vs_all'):\n",
    "    \n",
    "    A = data[:, (states_labels == main_state)[0,:]]\n",
    "    if mode == 'one_vs_all':\n",
    "        B = data[:, (states_labels != main_state)[0,:]]\n",
    "    elif mode == 'pairwise':\n",
    "        if other_state == None:\n",
    "            print(\"Other state must be specified\")\n",
    "            return None\n",
    "        else:\n",
    "            B = data[:, (states_labels == other_state)[0,:]]\n",
    "    \n",
    "    C1 = np.cov(A)\n",
    "    C2 = np.cov(B)\n",
    "    \n",
    "    return csp(C1,C2,N_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def const_features(data,states_labels,states_codes,sr,feat_type,freq_ranges,how_to_filt,N_csp_comp,win,order=5,normalize=False):\n",
    "    '''\n",
    "    Filters data according to specified bands (in freq_range) and derives CSP transformations for each band.\n",
    "    Type of CSP should be provided in feat_type: pairwise or one-vs-all (recommended).\n",
    "    Number of CSP components should be provided in N_csp_comp (for a given N, N first and N last components will be used).\n",
    "    Time interval for averaging is specified in win.\n",
    "    If normalize=True, each data point is in [0,1].\n",
    "    Returns array of transformed data, list of CSP transform matrices (in arrays), \n",
    "    and array of state codes for each of the final features (i.e., which state was first while this CSP projection was computed)\n",
    "    '''\n",
    "    final_data = np.zeros((1, data.shape[1]))\n",
    "    all_CSPs = []\n",
    "    where_states = []\n",
    "    \n",
    "    if feat_type == 'CSP_pairwise':\n",
    "        for freq in freq_ranges:\n",
    "            data_filt = butter_bandpass_filter(data, freq[0], freq[1], sr, order, how_to_filt)\n",
    "            all_states_CSP = []\n",
    "            for st in states_codes:\n",
    "                for oth_st in np.array(states_codes)[np.array(states_codes)!=st]:\n",
    "                    CSP_st = get_CSP_matr(data_filt, states_labels, st, N_csp_comp, other_state=oth_st, mode='pairwise')\n",
    "                    all_states_CSP.append(np.dot(CSP_st, data_filt))\n",
    "                    all_CSPs.append(CSP_st)\n",
    "                    where_states.extend([st]*(N_csp_comp*2))\n",
    "                data_transformed = np.vstack(all_states_CSP)**2\n",
    "            final_data = np.vstack((final_data, data_transformed))\n",
    "            \n",
    "    elif feat_type == 'CSP_one_vs_all':\n",
    "        for freq in freq_ranges:\n",
    "            data_filt = butter_bandpass_filter(data, freq[0], freq[1], sr, order, how_to_filt)\n",
    "            all_states_CSP = []\n",
    "            for st in states_codes:\n",
    "                CSP_st = get_CSP_matr(data_filt, states_labels, st, N_csp_comp, other_state=None, mode='one_vs_all')\n",
    "                all_states_CSP.append(np.dot(CSP_st, data_filt))\n",
    "                all_CSPs.append(CSP_st)\n",
    "                where_states.extend([st]*(N_csp_comp*2))\n",
    "            data_transformed = np.vstack(all_states_CSP)**2\n",
    "            final_data = np.vstack((final_data, data_transformed))\n",
    "            \n",
    "    elif feat_type == 'no_filt_no_csp':\n",
    "        final_data = np.vstack((final_data, data**2))\n",
    "\n",
    "    final_data = final_data[1:,:]\n",
    "    a_ma = 1\n",
    "    b_ma = np.ones(win)/float(win)\n",
    "    final_data = lfilter(b_ma, a_ma, final_data)\n",
    "    if normalize:\n",
    "        final_data = final_data/np.sum(final_data,0)[np.newaxis,:]\n",
    "    print('Shape of data matrix: ', final_data.shape)\n",
    "        \n",
    "    return final_data, all_CSPs, np.array(where_states)\n",
    "\n",
    "def filt_apply_CSPs(data, sr, freq_range, all_CSPs, how_to_filt, win, order=5, normalize=False, no_filt_no_csp=False):\n",
    "    '''\n",
    "    Filters data according to specified bands (in freq_range) and applies corresponding CSP transformations (in all_CSPs).\n",
    "    Order in freq_range and all_CSPs must be the same.\n",
    "    If normalize=True, each data point is in [0,1].\n",
    "    '''\n",
    "    if no_filt_no_csp == False:\n",
    "        N_csp_per_freq = len(all_CSPs)/len(freq_range)\n",
    "        all_CSPs_copy = list(all_CSPs)\n",
    "        transformed_data = np.zeros((1, data.shape[1]))\n",
    "        for fr_ind in range(len(freq_range)):\n",
    "            filt_data = butter_bandpass_filter(data,freq_range[fr_ind][0],freq_range[fr_ind][1],sr,order,how_to_filt)\n",
    "            for csp_ind in range(N_csp_per_freq):\n",
    "                transformed_data = np.vstack((transformed_data, np.dot(all_CSPs_copy.pop(0), filt_data)))\n",
    "        final_data = transformed_data[1:,:]**2\n",
    "        \n",
    "    elif no_filt_no_csp == True:\n",
    "        final_data = data**2\n",
    "        \n",
    "    a_ma = 1\n",
    "    b_ma = np.ones(win)/float(win)\n",
    "    final_data = lfilter(b_ma, a_ma, final_data)\n",
    "    if normalize:\n",
    "        final_data = final_data/np.sum(final_data,0)[np.newaxis,:]\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_eeg(eeg_data, sampling_rate, channel_names, states_codes):\n",
    "    # Prefilter eeg data\n",
    "    eeg_data = butter_bandpass_filter(eeg_data, 0.5, 45, sampling_rate, order=5, how_to_filt='separately')\n",
    "    \n",
    "    # Remove empty channels\n",
    "    # Detect constant (zero) channels\n",
    "    channels_mask = np.ones(len(channel_names), dtype=np.bool)\n",
    "    for channel in CHANNELS_TO_DISCARD:\n",
    "        channels_mask &= (channel_names != channel)\n",
    "    nozeros_mask = np.sum(eeg_data[:, :sampling_rate * 2], 1) != 0\n",
    "    without_emp_mask = nozeros_mask & channels_mask\n",
    "    \n",
    "    # Remove constant (zero) channels and prespecified channels\n",
    "    eeg_data = eeg_data[without_emp_mask, :]\n",
    "    used_channel_names = channel_names[without_emp_mask]\n",
    "\n",
    "    # Remove outliers; remove artifacts (blinks, eye movements)\n",
    "    eeg_data, mask = remove_outliers(eeg_data, 7)\n",
    "    eeg_data, M_eog = remove_eog_simple(eeg_data, used_channel_names == EYE_CHANNEL)\n",
    "    return eeg_data, mask\n",
    "    \n",
    "\n",
    "def extract_features(eeg_data, states_labels, states_codes, sampling_rate):\n",
    "    # Construct features: project eeg data on CSP components (separately for each of specified frequency bands)\n",
    "    N_CSP_comp = 3 # N first and N last; 2*N in total\n",
    "    window_to_sampling_rate = 2\n",
    "    win = sampling_rate // window_to_sampling_rate # Window for averaging: 0.5 sec\n",
    "    frequences = [(6,10),(8,12),(10,14),(12,16),(14,18),(16,20),(18,22),(20,24),\n",
    "                  (22,26),(24,28),(26,30),(28,32),(30,34),(32,36),(34,38)]\n",
    "    eeg_data, all_CSPs, where_states = const_features(eeg_data,states_labels,states_codes,sampling_rate,'CSP_one_vs_all',\n",
    "                                                        frequences,'separately',N_CSP_comp,win)\n",
    "    \n",
    "    return (eeg_data[:, sampling_rate:], states_labels[:, sampling_rate:], all_CSPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples left after outliers removal: 55584\n",
      "Samples left after outliers removal: 55063\n",
      "Samples left after outliers removal: 53226\n",
      "Samples left after outliers removal: 51529\n",
      "Samples left after outliers removal: 50303\n",
      "Samples left after outliers removal: 49438\n",
      "Samples left after outliers removal: 48866\n",
      "Number of samples identified as containing eye artifacts: 473\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4e2a0ede6835>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m             filtered_eeg, selected_items = filter_eeg(\n\u001b[1;32m      6\u001b[0m                 subject_data['data'], SAMPLING_RATE, CHANNEL_NAMES, states_codes)\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextrat_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_eeg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_codes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAMPLING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-1207e5d42c3a>\u001b[0m in \u001b[0;36mextrat_features\u001b[0;34m(eeg_data, states_labels, states_codes, sampling_rate)\u001b[0m\n\u001b[1;32m     29\u001b[0m                   (22,26),(24,28),(26,30),(28,32),(30,34),(32,36),(34,38)]\n\u001b[1;32m     30\u001b[0m     eeg_data, all_CSPs, where_states = const_features(eeg_data,states_labels,states_codes,sampling_rate,'CSP_one_vs_all',\n\u001b[0;32m---> 31\u001b[0;31m                                                         frequences,'separately',N_CSP_comp,win)\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meeg_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_CSPs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-5c9669f72105>\u001b[0m in \u001b[0;36mconst_features\u001b[0;34m(data, states_labels, states_codes, sr, feat_type, freq_ranges, how_to_filt, N_csp_comp, win, order, normalize)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mall_states_CSP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mst\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstates_codes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mCSP_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_CSP_matr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_filt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_csp_comp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'one_vs_all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mall_states_CSP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSP_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_filt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mall_CSPs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSP_st\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-e5fd6f33a513>\u001b[0m in \u001b[0;36mget_CSP_matr\u001b[0;34m(data, states_labels, main_state, N_comp, other_state, mode)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_CSP_matr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_comp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'one_vs_all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstates_labels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmain_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'one_vs_all'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstates_labels\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmain_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "with h5py.File(TRAIN_FILE, 'r') as data_file:\n",
    "    with h5py.File(TEST_FILE, 'r') as test_file:\n",
    "        for subject, subject_data in data_file.items():\n",
    "            states_codes = list(np.unique(subject_data['labels']))\n",
    "            filtered_eeg, selected_items = filter_eeg(\n",
    "                subject_data['data'], SAMPLING_RATE, CHANNEL_NAMES, states_codes)\n",
    "            print(extrat_features(filtered_eeg, subject_data['labels'], states_codes, SAMPLING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a= np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.in"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:neurohack_nov_2016]",
   "language": "python",
   "name": "conda-env-neurohack_nov_2016-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
